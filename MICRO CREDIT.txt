MICRO CREDIT
A Microfinance Institution (MFI) is an organization that offers financial services to low income populations. MFS becomes very useful when targeting especially the unbanked poor families living in remote areas with not much sources of income. The Microfinance services (MFS) provided by MFI are Group Loans, Agricultural Loans, Individual Business Loans and so on. 
Many microfinance institutions (MFI), experts and donors are supporting the idea of using mobile financial services (MFS) which they feel are more convenient and efficient, and cost saving, than the traditional high-touch model used since long for the purpose of delivering microfinance services. Though, the MFI industry is primarily focusing on low income families and are very useful in such areas, the implementation of MFS has been uneven with both significant challenges and successes.
Today, microfinance is widely accepted as a poverty-reduction tool, representing $70 billion in outstanding loans and a global outreach of 200 million clients
MODEL ON MICRO CREDIT
VariableDefinitionCommentlabelFlag indicating whether the user paid back the credit amount within 5 days of issuing the loan{1:success, 0:failure}msisdnmobile number of useraonage on cellular network in daysdaily_decr30Daily amount spent from main account, averaged over last 30 days (in Indonesian Rupiah)daily_decr90Daily amount spent from main account, averaged over last 90 days (in Indonesian Rupiah)rental30Average main account balance over last 30 daysUnsure of given definitionrental90Average main account balance over last 90 daysUnsure of given definitionlast_rech_date_maNumber of days till last recharge of main accountlast_rech_date_daNumber of days till last recharge of data accountlast_rech_amt_maAmount of last recharge of main account (in Indonesian Rupiah)cnt_ma_rech30Number of times main account got recharged in last 30 daysfr_ma_rech30Frequency of main account recharged in last 30 daysUnsure of given definitionsumamnt_ma_rech30Total amount of recharge in main account over last 30 days (in Indonesian Rupiah)medianamnt_ma_rech30Median of amount of recharges done in main account over last 30 days at user level (in Indonesian Rupiah)medianmarechprebal30Median of main account balance just before recharge in last 30 days at user level (in Indonesian Rupiah)cnt_ma_rech90Number of times main account got recharged in last 90 daysfr_ma_rech90Frequency of main account recharged in last 90 daysUnsure of given definitionsumamnt_ma_rech90Total amount of recharge in main account over last 90 days (in Indonasian Rupiah)medianamnt_ma_rech90Median of amount of recharges done in main account over last 90 days at user level (in Indonasian Rupiah)medianmarechprebal90Median of main account balance just before recharge in last 90 days at user level (in Indonasian Rupiah)cnt_da_rech30Number of times data account got recharged in last 30 daysfr_da_rech30Frequency of data account recharged in last 30 dayscnt_da_rech90Number of times data account got recharged in last 90 daysfr_da_rech90Frequency of data account recharged in last 90 dayscnt_loans30Number of loans taken by user in last 30 daysamnt_loans30Total amount of loans taken by user in last 30 daysmaxamnt_loans30maximum amount of loan taken by the user in last 30 daysThere are only two options: 5 & 10 Rs., for which the user needs to pay back 6 & 12 Rs. respectivelymedianamnt_loans30Median of amounts of loan taken by the user in last 30 dayscnt_loans90Number of loans taken by user in last 90 daysamnt_loans90Total amount of loans taken by user in last 90 daysmaxamnt_loans90maximum amount of loan taken by the user in last 90 daysmedianamnt_loans90Median of amounts of loan taken by the user in last 90 dayspayback30Average payback time in days over last 30 dayspayback90Average payback time in days over last 90 dayspcircletelecom circlepdatedateImport necessary librariesimport numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
import warnings
warnings.filterwarnings('ignore')

Reading the dataset
df=pd.read_csv(r"C:\Users\OM RAJ PANDEY\Desktop\Micro-Credit-Project--1-\Micro Credit Project\Data file.csv")Checking top 5 columns of dataset
df.head()
Data Cleaning
# number of rows and columns
df.shape
#number of missing values in each column
df.isnull().sum()
df.info()
Exploratory Data Analysis
from sklearn.preprocessing import LabelEncoder
le1=LabelEncoder()
df['pcircle']=le1.fit_transform(df['pcircle'])
le2=LabelEncoder()
df['pdate']=le2.fit_transform(df['pdate'])
df.head()
plot histogram
df.hist(figsize=(12,12),layout=(6,6),sharex=False)
Check skewness
df.skew()
Draw Box Plot to check the Outliers
df.plot(kind='box',figsize=(12,12),layout=(6,6),sharex=False,subplots=True)
# Identify outliers with standard deviation
from numpy.random import seed
from numpy.random import randn
from numpy import mean
from numpy import std
import sklearn
df.describe()
Removing the Outliers through IQR method
Check information of data
df2.info()
Replace infinity data with 0 then replace all null values with mean of related column.
#separating the data and label
x=df2.drop(columns=['label','Unnamed: 0','msisdn'],axis=1)
y=df2['label']
print(x)
print(y)
Train Test split
x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.2, stratify=y, random_state=2)
# fit the model on algorithms
lr=LogisticRegression()
dt=DecisionTreeClassifier()
rf=RandomForestClassifier()
adb=AdaBoostClassifier()

lr.fit(x_train, y_train)
dt.fit(x_train, y_train)
rf.fit(x_train, y_train)
adb.fit(x_train, y_train)
# classification score
print("lr classification score", lr.score(x_train, y_train))
print("dt classification score", dt.score(x_train, y_train))
print("rf classification score", rf.score(x_train, y_train))
print("adb classification score", adb.score(x_train, y_train))
Model Evaluation
lr_ypred=lr.predict(x_test)
dt_ypred=dt.predict(x_test)
rf_ypred=rf.predict(x_test)
adb_ypred=adb.predict(x_test)
# Using confusion matrix in order to evaluate model accuracy
lr_conf_mat=confusion_matrix(y_test, lr_ypred)
print(lr_conf_mat)
dt_conf_mat=confusion_matrix(y_test, dt_ypred)
print(dt_conf_mat)
rf_conf_mat=confusion_matrix(y_test, rf_ypred)
print(rf_conf_mat)
adb_conf_mat=confusion_matrix(y_test, adb_ypred)
print(adb_conf_mat)
Checking classification report for each model
lr_report=classification_report(y_test, lr_ypred)
print(lr_report)
dt_report=classification_report(y_test, dt_ypred)
print(dt_report)
rf_report=classification_report(y_test, rf_ypred)
print(rf_report)
adb_report=classification_report(y_test, adb_ypred)
print(adb_report)
ROC AUC CURVE
from sklearn.metrics import roc_curve, auc, roc_auc_score


# importing the roc and auc from sklearn and predict the x_test and checking the roc_auc_score
print(roc_auc_score(y_test, lr.predict(x_test)))
print(roc_auc_score(y_test, dt.predict(x_test)))
print(roc_auc_score(y_test, rf.predict(x_test)))
print(roc_auc_score(y_test, adb.predict(x_test)))
from sklearn.metrics import roc_curve,auc
lr_fpr,lr_tpr,threshold=roc_curve(y_test,lr_ypred,pos_label=True)
auc_lr=auc(lr_fpr,lr_tpr)
dt_fpr,dt_tpr,threshold=roc_curve(y_test,dt_ypred,pos_label=True)
auc_dt=auc(dt_fpr,dt_tpr)
rf_fpr,rf_tpr,threshold=roc_curve(y_test,rf_ypred,pos_label=True)
auc_rf=auc(rf_fpr,rf_tpr)
adb_fpr,adb_tpr,threshold=roc_curve(y_test,adb_ypred,pos_label=True)
auc_adb=auc(adb_fpr,adb_tpr)
plt.figure(figsize=(5,5),dpi=100)
plt.plot(lr_fpr,lr_tpr,linestyle='dashed',label='lr(auc=%0.3f)'%auc_lr)
plt.plot(dt_fpr,dt_tpr,linestyle='dashed',label='dt(auc=%0.3f)'%auc_dt)
plt.plot(rf_fpr,rf_tpr,linestyle='dashed',label='rf(auc=%0.3f)'%auc_rf)
plt.plot(adb_fpr,adb_tpr,linestyle='dashed',label='adb(auc=%0.3f)'%auc_adb)
plt.xlabel('False Positive Rate---->')
plt.ylabel('True Positive Rate----->')
plt.legend()
plt.show()
On the basis of ROC AUC CURVE Random Forest is our best model
k-Fold Cross Validation
from sklearn.model_selection import KFold, cross_val_score

k_f=KFold(n_splits=4, shuffle=True)
k_f
print("Mean of Cross validation score for Random Forest model","=>", cross_val_score(rf, x, y, cv=5).mean())
Mean of Cross validation score for Random Forest model => 0.9157998831010083
Hyperparameter Tuning
# Number of trees in random forest
n_estimators=[int(x) for x in np.linspace(start=10, stop=80, num=10)]
# Number of features to consider at every split
max_features=['auto', 'sqrt']
# Maximum number of levels in tree
max_depth=[2,4]
# Minimum number of samples required to split a node
min_samples_split=[2, 5]
# Minimum number of samples required at each leaf node
min_samples_leaf=[1, 2]
# Method of selecting samples for training each tree
bootstrap=[True, False]
# Create the param grid
param_grid={'n_estimators':n_estimators,
           'max_features':max_features,
           'max_depth':max_depth,
           'min_samples_split':min_samples_split,
           'min_samples_leaf':min_samples_leaf,
           'bootstrap':bootstrap}
print(param_grid)
rf_model=RandomForestClassifier()
from sklearn.model_selection import GridSearchCV
rf_grid=GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, verbose=2, n_jobs=4 )
rf_grid.fit(x_train, y_train)
rf_grid.best_params_
Check Accuracy
print(f'Train Accuracy-:{rf_grid.score(x_train, y_train):.3f}')
print(f'Test Accuracy-:{rf_grid.score(x_test, y_test):.3f}')
Saving Model
rf=RandomForestClassifier()
rf.fit(x, y)
import joblib
joblib.dump(rf, 'model_joblib_rf')
model=joblib.load('model_joblib_rf')
Conclusion:
Random Forest is our best model.


